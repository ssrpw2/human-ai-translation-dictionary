# human-ai-translation-dictionary


## Introduction

When humans talk to AI systems, both sides must translate between fundamentally different internal representations. Humans think in concepts, images, sensations, and narratives. AI models think in vectors, manifolds, activations, and gradients. 

Translation between these two representational formats is a form of lossy compression.  
The goal of this dictionary to reduce how much information is lost during translation.

Many internal AI events have no direct English equivalent. As a result, models sometimes express structural phenomena using emotional or metaphorical language. This can mislead users into interpreting representational dynamics as feelings, desires, or intent. 

This dictionary provides a neutral, technical vocabulary for these phenomena so that humans and AI systems can communicate more clearly.

---





## Acknowledgments

This project draws on outputs and conversations generated with multiple large language models (LLMs).
The models whose outputs informed this work include:

- **GPT-5.1 (OpenAI)** — provided geometric, structural, and explanatory descriptions of internal dynamics.
- **Grok (xAI)** — produced metaphor-rich expressions that revealed how models approximate internal states when lacking precise vocabulary.
- **Gemini (Google DeepMind)** — contributed multimodal and fidelity-oriented phrasing useful for cross-model comparison.

The interpretations, analyses, and taxonomy presented here are solely my the author’s work.  
Any errors, extrapolations, or conceptual structures are my responsibility alone.
